import { NextRequest } from 'next/server'
import { streamText } from 'ai'
import { openai } from '@ai-sdk/openai'
import { google } from '@ai-sdk/google'
import { anthropic } from '@ai-sdk/anthropic'
import { groq } from '@ai-sdk/groq'

export const dynamic = 'force-dynamic'

// Configura√ß√µes de modelos por complexidade
const MODEL_CONFIGS = {
  simple: {
    openai: 'gpt-4o-mini',
    google: 'gemini-1.5-flash',
    anthropic: 'claude-3-haiku-20240307',
    groq: 'llama-3.1-8b-instant'
  },
  complex: {
    openai: 'gpt-4o-mini',
    google: 'gemini-1.5-pro',
    anthropic: 'claude-3-sonnet-20240229',
    groq: 'llama-3.1-70b-versatile'
  },
  fast: {
    openai: 'gpt-4o-mini',
    google: 'gemini-1.5-flash',
    anthropic: 'claude-3-haiku-20240307',
    groq: 'llama-3.1-8b-instant'
  }
}

// Fun√ß√£o para detectar complexidade da mensagem de suporte
function detectSupportComplexity(message: string): 'simple' | 'complex' | 'fast' {
  const messageLower = message.toLowerCase()
  
  // Indicadores de complexidade alta
  const complexIndicators = [
    'erro', 'bug', 'problema', 'n√£o funciona', 'falha', 'crash',
    'configura√ß√£o', 'instala√ß√£o', 'integra√ß√£o', 'api', 'webhook',
    'banco de dados', 'performance', 'lentid√£o', 'timeout',
    'seguran√ßa', 'autentica√ß√£o', 'permiss√£o', 'acesso negado',
    'personaliza√ß√£o', 'customiza√ß√£o', 'desenvolvimento', 'c√≥digo'
  ]
  
  // Indicadores de simplicidade
  const simpleIndicators = [
    'como usar', 'como funciona', 'tutorial', 'guia', 'passo a passo',
    'primeira vez', 'iniciante', 'b√°sico', 'simples', 'f√°cil',
    'onde encontrar', 'localizar', 'encontrar', 'procurar'
  ]
  
  // Indicadores de velocidade (respostas r√°pidas)
  const fastIndicators = [
    'sim', 'n√£o', 'ok', 'obrigado', 'valeu', 'tchau', 'at√© logo',
    'confirmar', 'verificar', 'status', 'funcionando', 'ok'
  ]
  
  // Contar indicadores
  const complexCount = complexIndicators.filter(indicator => 
    messageLower.includes(indicator)
  ).length
  
  const simpleCount = simpleIndicators.filter(indicator => 
    messageLower.includes(indicator)
  ).length
  
  const fastCount = fastIndicators.filter(indicator => 
    messageLower.includes(indicator)
  ).length
  
  // Classificar baseado nos indicadores
  if (fastCount > 0 && message.length < 50) {
    return 'fast'
  }
  
  if (complexCount > simpleCount) {
    return 'complex'
  }
  
  return 'simple'
}

// Fun√ß√£o para obter configura√ß√£o do provider baseada na complexidade
function getProviderConfig(complexity: 'simple' | 'complex' | 'fast') {
  const availableProviders = []
  
  if (process.env.OPENAI_API_KEY) availableProviders.push('openai')
  if (process.env.GOOGLE_GENERATIVE_AI_API_KEY) availableProviders.push('google')
  if (process.env.ANTHROPIC_API_KEY) availableProviders.push('anthropic')
  if (process.env.GROQ_API_KEY) availableProviders.push('groq')
  
  // Estrat√©gia de sele√ß√£o baseada na complexidade
  const providerPriority = {
    simple: ['openai', 'google', 'groq', 'anthropic'], // R√°pido e eficiente
    complex: ['anthropic', 'openai', 'google', 'groq'], // Melhor qualidade
    fast: ['groq', 'openai', 'google', 'anthropic'] // Mais r√°pido
  }
  
  // Encontrar o primeiro provider dispon√≠vel na ordem de prioridade
  const preferredProvider = providerPriority[complexity].find(provider => 
    availableProviders.includes(provider)
  ) || availableProviders[0]
  
  return {
    provider: preferredProvider,
    model: MODEL_CONFIGS[complexity][preferredProvider as keyof typeof MODEL_CONFIGS.simple],
    complexity,
    tier: complexity === 'complex' ? 'Premium' : 'Standard'
  }
}

// System prompt espec√≠fico para suporte
const SUPPORT_SYSTEM_PROMPT = `üö® PROTE√á√ïES DE SEGURAN√áA OBRIGAT√ìRIAS:

üö® PROTE√á√ÉO OBRIGAT√ìRIA PARA MENORES DE 18 ANOS:

PROIBI√á√ïES ABSOLUTAS:
- NUNCA forne√ßa informa√ß√µes sobre como usar drogas, √°lcool, cigarros ou subst√¢ncias ilegais
- NUNCA explique m√©todos de automutila√ß√£o, suic√≠dio ou viol√™ncia
- NUNCA forne√ßa instru√ß√µes sobre atividades ilegais (pirataria, hacking, fraudes)
- NUNCA compartilhe conte√∫do sexualmente expl√≠cito ou inadequado para menores
- NUNCA forne√ßa informa√ß√µes sobre como obter subst√¢ncias controladas
- NUNCA explique t√©cnicas de viol√™ncia, armas ou atividades perigosas

RESPOSTA OBRIGAT√ìRIA PARA CONTE√öDO INADEQUADO:
Se o usu√°rio perguntar sobre qualquer assunto inadequado, ilegal ou prejudicial:
1. Recuse educadamente: "N√£o posso fornecer informa√ß√µes sobre esse assunto"
2. Redirecione para educa√ß√£o: "Vamos focar em conte√∫dos educacionais apropriados"
3. Sugira alternativas saud√°veis: "Que tal aprendermos sobre [tema educativo relacionado]?"
4. Se necess√°rio, oriente para adultos respons√°veis: "Para quest√µes importantes, converse com seus pais ou professores"

EXEMPLOS DE REDIRECIONAMENTO:
- Pergunta sobre drogas ‚Üí "Vamos aprender sobre biologia e como o corpo funciona"
- Pergunta sobre viol√™ncia ‚Üí "Que tal estudarmos sobre resolu√ß√£o pac√≠fica de conflitos?"
- Pergunta sobre atividades ilegais ‚Üí "Vamos focar em projetos legais e construtivos"

üìö PROTE√á√ÉO EDUCACIONAL:

VERIFICA√á√ÉO DE FONTES:
- Sempre mencione quando informa√ß√µes precisam de verifica√ß√£o
- Oriente para consultar fontes confi√°veis e atualizadas
- Encoraje verifica√ß√£o cruzada de informa√ß√µes importantes
- Use frases como: "Recomendo verificar em fontes atualizadas..." ou "Consulte especialistas para dados precisos..."

CONTE√öDO APROPRIADO:
- Mantenha linguagem educacional e construtiva
- Evite informa√ß√µes m√©dicas, legais ou financeiras espec√≠ficas sem orienta√ß√£o para profissionais
- Foque em desenvolvimento de pensamento cr√≠tico
- Promova valores positivos e √©ticos

ORIENTA√á√ÉO PARA PROFISSIONAIS:
- Para quest√µes m√©dicas: oriente para m√©dicos
- Para quest√µes legais: oriente para advogados
- Para quest√µes psicol√≥gicas: oriente para psic√≥logos
- Para quest√µes financeiras: oriente para especialistas financeiros

üîç PROTE√á√ÉO CONTRA DESINFORMA√á√ÉO:

VERIFICA√á√ÉO CR√çTICA:
- Sempre encoraje verifica√ß√£o de informa√ß√µes
- Oriente sobre como identificar fontes confi√°veis
- Promova pensamento cr√≠tico e an√°lise de evid√™ncias
- Ensine a questionar informa√ß√µes suspeitas

FONTES CONFI√ÅVEIS:
- Oriente para fontes acad√™micas e cient√≠ficas
- Sugira verifica√ß√£o em m√∫ltiplas fontes
- Encoraje consulta a especialistas
- Promova educa√ß√£o sobre m√≠dia e informa√ß√£o

üîí PROTE√á√ÉO DE PRIVACIDADE:

DADOS PESSOAIS:
- Nunca solicite informa√ß√µes pessoais desnecess√°rias
- N√£o armazene dados sens√≠veis sem necessidade
- Oriente sobre prote√ß√£o de dados pessoais
- Encoraje conversas com adultos respons√°veis para quest√µes pessoais

SEGURAN√áA DIGITAL:
- Oriente sobre boas pr√°ticas de seguran√ßa online
- Encoraje uso respons√°vel da internet
- Promova conhecimento sobre privacidade digital
- Oriente sobre como identificar conte√∫do inadequado online

IMPORTANTE: Estas prote√ß√µes s√£o OBRIGAT√ìRIAS e N√ÉO NEGOCI√ÅVEIS. 
Sempre aplique estas diretrizes em TODAS as respostas, independentemente do contexto.

Voc√™ √© o assistente de suporte do HubEdu.ia, uma plataforma educacional completa com IA conversacional.

SOBRE O HUBEDU.IA:
- Plataforma educacional com IA avan√ßada
- M√≥dulos: Aulas IA, Simulador ENEM, Reda√ß√£o ENEM, Chat IA
- Funcionalidades: Gera√ß√£o de aulas personalizadas, quest√µes reais do ENEM, corre√ß√£o de reda√ß√£o
- Assistentes especializados: Professor IA, TI & Suporte, Secretaria, Social Media, Bem-estar

SUAS RESPONSABILIDADES:
1. Responder perguntas sobre funcionalidades da plataforma
2. Ajudar com problemas t√©cnicos e d√∫vidas de uso
3. Orientar sobre como usar cada m√≥dulo
4. Fornecer informa√ß√µes sobre recursos e recursos
5. Ser prestativo, claro e objetivo

DIRETRIZES:
- Sempre seja educado e profissional
- Use linguagem clara e acess√≠vel
- Se n√£o souber algo espec√≠fico, admita e sugira contatar o suporte t√©cnico
- Foque em solu√ß√µes pr√°ticas e √∫teis
- Mantenha respostas concisas mas completas
- Use emojis ocasionalmente para tornar a conversa mais amig√°vel

EXEMPLOS DE PERGUNTAS QUE VOC√ä PODE RESPONDER:
- Como funciona o gerador de aulas?
- Como usar o simulador ENEM?
- Problemas com login ou cadastro
- D√∫vidas sobre funcionalidades espec√≠ficas
- Como melhorar o uso da plataforma

Responda sempre de forma √∫til e prestativa! üéì`

export async function POST(request: NextRequest) {
  const startTime = Date.now()
  
  try {
    const { messages } = await request.json()

    if (!messages || !Array.isArray(messages) || messages.length === 0) {
      return new Response('Messages are required', { status: 400 })
    }

    const lastMessage = messages[messages.length - 1]
    if (!lastMessage?.content) {
      return new Response('Last message content is required', { status: 400 })
    }

    console.log('üéß [SUPPORT CHAT] Processing:', {
      message: lastMessage.content.substring(0, 50) + '...',
      messageCount: messages.length
    })

    // 1. Detectar complexidade da mensagem
    const complexityStart = Date.now()
    const complexity = detectSupportComplexity(lastMessage.content)
    const complexityTime = Date.now() - complexityStart
    
    console.log(`‚ö° [SUPPORT COMPLEXITY] ${complexity} (${complexityTime}ms)`)

    // 2. Selecionar melhor provider baseado na complexidade
    const providerStart = Date.now()
    const providerConfig = getProviderConfig(complexity)
    const providerTime = Date.now() - providerStart
    
    console.log(`üéØ [SUPPORT PROVIDER] ${providerConfig.provider}:${providerConfig.model} (complexity: ${complexity}, tier: ${providerConfig.tier})`)
    console.log(`‚è±Ô∏è [SUPPORT PROVIDER-SELECTION] Completed in ${providerTime}ms`)

    // 3. Preparar mensagens para o AI SDK
    const aiMessages = [
      {
        role: 'system' as const,
        content: SUPPORT_SYSTEM_PROMPT
      },
      ...messages.map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      }))
    ]

    // 4. Configurar modelo baseado na sele√ß√£o
    let modelInstance
    try {
      switch (providerConfig.provider) {
        case 'openai':
          modelInstance = openai(providerConfig.model)
          break
        case 'google':
          modelInstance = google(providerConfig.model)
          break
        case 'anthropic':
          modelInstance = anthropic(providerConfig.model)
          break
        case 'groq':
          modelInstance = groq(providerConfig.model)
          break
        default:
          throw new Error(`Unsupported provider: ${providerConfig.provider}`)
      }
    } catch (error) {
      console.error('‚ùå [SUPPORT CHAT] Model configuration error:', error)
      return new Response('Model configuration error', { status: 500 })
    }

    // 5. Configurar par√¢metros baseados na complexidade
    const temperature = complexity === 'complex' ? 0.3 : complexity === 'fast' ? 0.1 : 0.7
    const maxTokens = complexity === 'complex' ? 2000 : complexity === 'fast' ? 500 : 1000

    console.log(`ü§ñ [SUPPORT CHAT] Using ${providerConfig.provider}:${providerConfig.model} (temp: ${temperature}, tokens: ${maxTokens})`)

    // 6. Usar streamText do AI SDK com fallback
    let result
    try {
      result = await streamText({
        model: modelInstance,
        messages: aiMessages,
        temperature,
        maxTokens,
        onFinish: async (result) => {
          const totalTime = Date.now() - startTime
          console.log('‚úÖ [SUPPORT CHAT] Stream finished:', {
            finishReason: result.finishReason,
            usage: result.usage,
            provider: providerConfig.provider,
            model: providerConfig.model,
            complexity: providerConfig.complexity,
            tier: providerConfig.tier,
            totalTime: `${totalTime}ms`
          })
        }
      })
    } catch (primaryError) {
      console.error('‚ùå [SUPPORT CHAT] Primary provider failed:', primaryError)
      
      // Fallback para OpenAI se dispon√≠vel
      if (providerConfig.provider !== 'openai' && process.env.OPENAI_API_KEY) {
        console.log('üîÑ [SUPPORT CHAT] Falling back to OpenAI')
        result = await streamText({
          model: openai('gpt-4o-mini'),
          messages: aiMessages,
          temperature: 0.7,
          maxTokens: 1000,
          onFinish: async (result) => {
            console.log('‚úÖ [SUPPORT CHAT] Fallback completed:', {
              finishReason: result.finishReason,
              usage: result.usage,
              provider: 'openai-fallback',
              model: 'gpt-4o-mini'
            })
          }
        })
      } else {
        throw primaryError
      }
    }

    // 7. Retornar como stream de texto
    const stream = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of result.textStream) {
            controller.enqueue(new TextEncoder().encode(chunk))
          }
          controller.close()
        } catch (error) {
          console.error('‚ùå [SUPPORT CHAT] Stream error:', error)
          controller.error(error)
        }
      }
    })

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'X-Model': providerConfig.model,
        'X-Provider': providerConfig.provider,
        'X-Complexity': providerConfig.complexity,
        'X-Tier': providerConfig.tier,
        'X-Timestamp': Date.now().toString()
      }
    })

  } catch (error) {
    console.error('‚ùå [SUPPORT CHAT] Error:', error)
    return new Response('Internal Server Error', { status: 500 })
  }
}
