import { NextRequest, NextResponse } from 'next/server'
import { GoogleGenerativeAI } from '@google/generative-ai'
import { getServerSession } from 'next-auth'
import { authOptions } from '@/lib/auth'

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!)

export const dynamic = 'force-dynamic'

export async function POST(request: NextRequest) {
  try {
    const session = await getServerSession(authOptions)
    if (!session) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    if (!process.env.GEMINI_API_KEY) {
      return NextResponse.json({
        error: 'Gemini API key not configured'
      }, { status: 500 })
    }

    const formData = await request.formData()
    const audioFile = formData.get('audio') as File

    if (!audioFile) {
      return NextResponse.json({ error: 'No audio file provided' }, { status: 400 })
    }

    console.log(`üé§ [DICTATION] Processing audio file: ${audioFile.name} (${audioFile.size} bytes)`)

    // Converter arquivo para base64
    const audioBuffer = await audioFile.arrayBuffer()
    const audioBase64 = Buffer.from(audioBuffer).toString('base64')
    const mimeType = audioFile.type || 'audio/webm'

    // Use Gemini 2.0 Flash para transcri√ß√£o
    const model = genAI.getGenerativeModel({ 
      model: 'gemini-2.0-flash-exp',
      generationConfig: {
        maxOutputTokens: 1024,
        temperature: 0.3, // Baixa temperatura para transcri√ß√£o mais precisa
      }
    })

    const prompt = `Transcreva este √°udio para texto em portugu√™s brasileiro. 
    
INSTRU√á√ïES:
1. Transcreva APENAS o que foi falado, sem adicionar pontua√ß√£o desnecess√°ria
2. Mantenha a naturalidade da fala
3. Corrija erros de pron√∫ncia quando √≥bvio
4. Use pontua√ß√£o b√°sica (v√≠rgulas, pontos) quando apropriado
5. Se houver pausas longas, indique com retic√™ncias (...)
6. Se n√£o conseguir entender algo, use [inaud√≠vel]
7. Responda APENAS com o texto transcrito, sem explica√ß√µes adicionais

TRANSCRI√á√ÉO:`

    try {
      const result = await model.generateContent([
        {
          text: prompt
        },
        {
          inlineData: {
            mimeType,
            data: audioBase64
          }
        }
      ])

      const response = await result.response
      const transcribedText = response.text().trim()

      console.log(`‚úÖ [DICTATION] Transcription completed: ${transcribedText.substring(0, 100)}...`)

      return NextResponse.json({
        success: true,
        text: transcribedText,
        timestamp: new Date().toISOString(),
        duration: audioFile.size / 1000 // Estimativa de dura√ß√£o
      })

    } catch (error: any) {
      console.error('‚ùå [DICTATION] Error generating transcription:', error)
      return NextResponse.json({
        error: 'Failed to transcribe audio',
        details: error.message
      }, { status: 500 })
    }

  } catch (error: any) {
    console.error('‚ùå [DICTATION] Processing error:', error)
    return NextResponse.json({
      error: 'Failed to process audio',
      details: error.message
    }, { status: 500 })
  }
}
