import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';
import textToSpeech from '@google-cloud/text-to-speech';

export const dynamic = 'force-dynamic';

/**
 * API Route: Gemini Live Voice
 * 
 * Processa √°udio do usu√°rio e retorna resposta em texto e √°udio
 */
export async function POST(req: NextRequest) {
  try {
    const formData = await req.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      return NextResponse.json(
        { error: 'Arquivo de √°udio √© obrigat√≥rio' },
        { status: 400 }
      );
    }

    // Get API key
    const apiKey = process.env.GOOGLE_GEMINI_API_KEY || 
                   process.env.GEMINI_API_KEY || 
                   process.env.GOOGLE_GENERATIVE_AI_API_KEY;

    if (!apiKey) {
      return NextResponse.json(
        { error: 'Chave da API Gemini n√£o configurada' },
        { status: 500 }
      );
    }

    console.log('üé§ [LIVE-VOICE] Processando √°udio:', audioFile.size, 'bytes');

    // Convert audio to base64
    const arrayBuffer = await audioFile.arrayBuffer();
    const base64Audio = Buffer.from(arrayBuffer).toString('base64');

    // Initialize Gemini
    const genAI = new GoogleGenerativeAI(apiKey);
    
    // Step 1: Transcrever √°udio com Gemini
    console.log('üîÑ [LIVE-VOICE] Transcrevendo √°udio...');
    const transcriptionModel = genAI.getGenerativeModel({ 
      model: 'gemini-2.5-flash' 
    });

    const transcriptionResult = await transcriptionModel.generateContent([
      {
        inlineData: {
          mimeType: audioFile.type || 'audio/webm',
          data: base64Audio
        }
      },
      'Transcreva este √°udio em portugu√™s brasileiro. Retorne apenas a transcri√ß√£o, sem coment√°rios adicionais.'
    ]);

    const transcription = transcriptionResult.response.text().trim();
    console.log('üìù [LIVE-VOICE] Transcri√ß√£o:', transcription);

    if (!transcription) {
      return NextResponse.json(
        { error: 'N√£o foi poss√≠vel transcrever o √°udio' },
        { status: 500 }
      );
    }

    // Step 2: Gerar resposta inteligente
    console.log('ü§ñ [LIVE-VOICE] Gerando resposta...');
    const responseModel = genAI.getGenerativeModel({
      model: 'gemini-2.5-flash',
      generationConfig: {
        temperature: 0.9,
        maxOutputTokens: 2048,
      },
    });

    const prompt = `Voc√™ √© um assistente de voz amig√°vel e conversacional. 
O usu√°rio disse: "${transcription}"

Responda de forma natural, conversacional e concisa (m√°ximo 3-4 frases). 
Se for uma pergunta, responda diretamente. 
Se for uma sauda√ß√£o, responda de forma amig√°vel.
Seja √∫til e emp√°tico.`;

    const responseResult = await responseModel.generateContent(prompt);
    const textResponse = responseResult.response.text();
    console.log('‚úÖ [LIVE-VOICE] Resposta gerada:', textResponse.substring(0, 100));

    // Step 3: Gerar √°udio da resposta
    console.log('üîä [LIVE-VOICE] Gerando √°udio da resposta...');
    let audioBase64: string | null = null;

    try {
      const ttsClient = new textToSpeech.TextToSpeechClient({
        apiKey: apiKey,
      });

      const [ttsResponse] = await ttsClient.synthesizeSpeech({
        input: { text: textResponse },
        voice: {
          languageCode: 'pt-BR',
          name: 'pt-BR-Neural2-A',
          ssmlGender: 'FEMALE' as const,
        },
        audioConfig: {
          audioEncoding: 'MP3',
          speakingRate: 1.1,
          pitch: 0,
        },
      });

      if (ttsResponse.audioContent) {
        audioBase64 = Buffer.from(ttsResponse.audioContent as Uint8Array).toString('base64');
        console.log('üéµ [LIVE-VOICE] √Åudio gerado com sucesso');
      }
    } catch (ttsError: any) {
      console.error('‚ö†Ô∏è [LIVE-VOICE] Erro ao gerar √°udio:', ttsError.message);
      // Continuar sem √°udio
    }

    return NextResponse.json({
      transcription,
      text: textResponse,
      audio: audioBase64,
      audioFormat: 'audio/mp3',
      timestamp: new Date().toISOString(),
    });

  } catch (error: any) {
    console.error('‚ùå [LIVE-VOICE] Erro:', error);
    
    return NextResponse.json(
      {
        error: 'Erro ao processar √°udio',
        details: error.message,
      },
      { status: 500 }
    );
  }
}

export async function GET() {
  return NextResponse.json({
    status: 'ok',
    service: 'gemini-live-voice',
    version: '1.0.0',
  });
}

