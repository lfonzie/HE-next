# ğŸ¤ AnÃ¡lise da Estrutura de Streaming de Ãudio - Live Audio

## ğŸ“‹ VisÃ£o Geral

A pasta `live-audio` contÃ©m uma implementaÃ§Ã£o completa de streaming de Ã¡udio em tempo real usando o Gemini 2.5 Flash Preview Native Audio Dialog. Esta implementaÃ§Ã£o serve como uma base sÃ³lida para entender como implementar streaming de Ã¡udio na pÃ¡gina `live-stream`.

## ğŸ—ï¸ Arquitetura da ImplementaÃ§Ã£o

### 1. **Componente Principal (`index.tsx`)**
- **Framework**: Lit Element (Web Components)
- **Modelo**: `gemini-2.5-flash-preview-native-audio-dialog`
- **Funcionalidade**: Streaming bidirecional de Ã¡udio em tempo real

### 2. **Contextos de Ãudio**
```typescript
// Contextos separados para entrada e saÃ­da
private inputAudioContext = new AudioContext({sampleRate: 16000});
private outputAudioContext = new AudioContext({sampleRate: 24000});
```

### 3. **NÃ³s de Ãudio**
```typescript
@state() inputNode = this.inputAudioContext.createGain();
@state() outputNode = this.outputAudioContext.createGain();
```

## ğŸµ Como o Ãudio Ã© Recebido via Streaming

### 1. **Captura de Microfone**
```typescript
private async startRecording() {
  // Solicita acesso ao microfone
  this.mediaStream = await navigator.mediaDevices.getUserMedia({
    audio: true,
    video: false,
  });

  // Cria fonte de Ã¡udio
  this.sourceNode = this.inputAudioContext.createMediaStreamSource(this.mediaStream);
  this.sourceNode.connect(this.inputNode);
}
```

### 2. **Processamento de Ãudio em Tempo Real**
```typescript
// ScriptProcessor para capturar chunks de Ã¡udio
const bufferSize = 256;
this.scriptProcessorNode = this.inputAudioContext.createScriptProcessor(
  bufferSize, 1, 1
);

this.scriptProcessorNode.onaudioprocess = (audioProcessingEvent) => {
  if (!this.isRecording) return;

  const inputBuffer = audioProcessingEvent.inputBuffer;
  const pcmData = inputBuffer.getChannelData(0);

  // Envia dados PCM para a API
  this.session.sendRealtimeInput({media: createBlob(pcmData)});
};
```

### 3. **ConversÃ£o PCM para Blob**
```typescript
// utils.ts - ConversÃ£o de Float32Array para Int16Array
function createBlob(data: Float32Array): Blob {
  const l = data.length;
  const int16 = new Int16Array(l);
  for (let i = 0; i < l; i++) {
    // Converte float32 (-1 a 1) para int16 (-32768 a 32767)
    int16[i] = data[i] * 32768;
  }

  return {
    data: encode(new Uint8Array(int16.buffer)),
    mimeType: 'audio/pcm;rate=16000',
  };
}
```

## ğŸš€ Como a Voz Ã© Enviada para a API

### 1. **ConexÃ£o com Gemini Live API**
```typescript
private async initSession() {
  this.session = await this.client.live.connect({
    model: 'gemini-2.5-flash-preview-native-audio-dialog',
    callbacks: {
      onopen: () => this.updateStatus('Opened'),
      onmessage: async (message: LiveServerMessage) => {
        // Processa resposta de Ã¡udio
        const audio = message.serverContent?.modelTurn?.parts[0]?.inlineData;
        if (audio) {
          // Decodifica e reproduz Ã¡udio recebido
          const audioBuffer = await decodeAudioData(
            decode(audio.data),
            this.outputAudioContext,
            24000, 1
          );
          // Reproduz Ã¡udio
          this.playAudioBuffer(audioBuffer);
        }
      },
      onerror: (e: ErrorEvent) => this.updateError(e.message),
      onclose: (e: CloseEvent) => this.updateStatus('Close:' + e.reason),
    },
    config: {
      responseModalities: [Modality.AUDIO],
      speechConfig: {
        voiceConfig: {prebuiltVoiceConfig: {voiceName: 'Orus'}},
      },
    },
  });
}
```

### 2. **Envio de Dados PCM**
```typescript
// Envio contÃ­nuo de chunks de Ã¡udio
this.session.sendRealtimeInput({media: createBlob(pcmData)});
```

### 3. **ConfiguraÃ§Ã£o de Resposta**
- **Modality.AUDIO**: Configura para receber Ã¡udio como resposta
- **Voice**: Usa voz prÃ©-configurada 'Orus'
- **Sample Rate**: 24000 Hz para saÃ­da

## ğŸ¨ Sistema de VisualizaÃ§Ã£o 3D

### 1. **Analisador de FrequÃªncia**
```typescript
export class Analyser {
  private analyser: AnalyserNode;
  private bufferLength = 0;
  private dataArray: Uint8Array;

  constructor(node: AudioNode) {
    this.analyser = node.context.createAnalyser();
    this.analyser.fftSize = 32;
    this.bufferLength = this.analyser.frequencyBinCount;
    this.dataArray = new Uint8Array(this.bufferLength);
    node.connect(this.analyser);
  }

  update() {
    this.analyser.getByteFrequencyData(this.dataArray);
  }
}
```

### 2. **VisualizaÃ§Ã£o 3D com Three.js**
- **Esfera animada**: Reage ao Ã¡udio de entrada e saÃ­da
- **Shaders personalizados**: Efeitos visuais baseados em frequÃªncia
- **Bloom e pÃ³s-processamento**: Efeitos visuais avanÃ§ados

## ğŸ”„ Fluxo Completo de Streaming

```mermaid
graph TD
    A[Microfone] --> B[MediaStream]
    B --> C[MediaStreamSource]
    C --> D[ScriptProcessor]
    D --> E[PCM Data]
    E --> F[createBlob]
    F --> G[session.sendRealtimeInput]
    G --> H[Gemini API]
    H --> I[Audio Response]
    I --> J[decodeAudioData]
    J --> K[AudioBuffer]
    K --> L[AudioBufferSource]
    L --> M[Speaker]
    
    N[Analyser] --> O[Frequency Data]
    O --> P[3D Visualization]
```

## ğŸ¯ DiferenÃ§as com Live-Stream Atual

### Live-Audio (Base)
- âœ… **Streaming nativo**: Usa Gemini Live API diretamente
- âœ… **Ãudio bidirecional**: Entrada e saÃ­da em tempo real
- âœ… **Processamento PCM**: ConversÃ£o direta de Ã¡udio
- âœ… **VisualizaÃ§Ã£o 3D**: AnÃ¡lise de frequÃªncia em tempo real
- âœ… **Web Components**: Arquitetura modular com Lit

### Live-Stream (Atual)
- âŒ **API intermediÃ¡ria**: Usa endpoints Next.js
- âŒ **MediaRecorder**: GravaÃ§Ã£o em chunks
- âŒ **Base64 encoding**: ConversÃ£o para texto
- âŒ **Interface React**: Componentes React tradicionais
- âŒ **Sem visualizaÃ§Ã£o**: Apenas controles bÃ¡sicos

## ğŸš€ Plano de IntegraÃ§Ã£o

### 1. **MigraÃ§Ã£o de Arquitetura**
- Implementar conexÃ£o direta com Gemini Live API
- Substituir MediaRecorder por ScriptProcessor
- Implementar streaming PCM nativo

### 2. **Melhorias de Performance**
- Usar AudioContext otimizado
- Implementar buffer management
- Adicionar anÃ¡lise de frequÃªncia

### 3. **Funcionalidades AvanÃ§adas**
- VisualizaÃ§Ã£o 3D baseada em Ã¡udio
- Controles de voz em tempo real
- InterrupÃ§Ã£o inteligente de Ã¡udio

## ğŸ“Š EspecificaÃ§Ãµes TÃ©cnicas

| Aspecto | Live-Audio | Live-Stream Atual |
|---------|------------|-------------------|
| **Sample Rate Input** | 16000 Hz | VariÃ¡vel |
| **Sample Rate Output** | 24000 Hz | N/A |
| **Buffer Size** | 256 samples | Chunks de 3s |
| **LatÃªncia** | ~16ms | ~3000ms |
| **Formato** | PCM nativo | WebM/Base64 |
| **API** | Gemini Live | REST endpoints |

## ğŸ‰ ConclusÃ£o

A implementaÃ§Ã£o `live-audio` oferece uma base sÃ³lida para streaming de Ã¡udio em tempo real com:

1. **Performance superior**: LatÃªncia muito menor
2. **Qualidade de Ã¡udio**: Processamento PCM nativo
3. **ExperiÃªncia imersiva**: VisualizaÃ§Ã£o 3D reativa
4. **Arquitetura moderna**: Web Components modulares

Esta estrutura deve ser usada como referÃªncia para modernizar a pÃ¡gina `live-stream` atual, implementando streaming nativo de Ã¡udio com visualizaÃ§Ãµes avanÃ§adas.

