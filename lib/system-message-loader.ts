// lib/system-message-loader.ts
// Sistema para carregar prompts espec√≠ficos do arquivo system-message.json

import fs from 'fs'
import path from 'path'

export interface SystemMessageConfig {
  name: string
  description: string
  system_prompt: string
  temperature: number
  max_tokens: number
  max_completion_tokens: number
  tone: string
  is_active: boolean
}

export interface SystemMessagesConfig {
  [module: string]: SystemMessageConfig
}

// Cache para evitar leitura repetida do arquivo
let systemMessagesCache: SystemMessagesConfig | null = null
let lastModified: number = 0

/**
 * Carrega as configura√ß√µes de mensagens do sistema do arquivo JSON
 */
export function loadSystemMessages(): SystemMessagesConfig {
  const filePath = path.join(process.cwd(), 'system-message.json')
  
  try {
    // Verificar se o arquivo foi modificado
    const stats = fs.statSync(filePath)
    const currentModified = stats.mtime.getTime()
    
    // Se o arquivo n√£o foi modificado e temos cache, retornar cache
    if (systemMessagesCache && currentModified === lastModified) {
      return systemMessagesCache
    }
    
    // Ler arquivo JSON
    const fileContent = fs.readFileSync(filePath, 'utf-8')
    const config = JSON.parse(fileContent) as SystemMessagesConfig
    
    // Atualizar cache
    systemMessagesCache = config
    lastModified = currentModified
    
    console.log('‚úÖ System messages loaded from JSON file')
    return config
    
  } catch (error) {
    console.error('‚ùå Error loading system messages:', error)
    
    // Retornar configura√ß√£o padr√£o em caso de erro
    return getDefaultSystemMessages()
  }
}

/**
 * Obt√©m o prompt do sistema para um m√≥dulo espec√≠fico
 */
export function getSystemPrompt(module: string = 'professor'): string {
  const config = loadSystemMessages()
  
  // Primeiro, tentar encontrar no chat_modules
  const chatModuleConfig = config.chat_modules?.[module]
  if (chatModuleConfig && chatModuleConfig.is_active) {
    return chatModuleConfig.system_prompt
  }
  
  // Se n√£o encontrou, tentar em outras categorias
  const allCategories = ['classification', 'api_routes', 'interactive_lessons', 'specialized_features']
  for (const category of allCategories) {
    const categoryConfig = config[category]?.[module]
    if (categoryConfig && categoryConfig.is_active) {
      return categoryConfig.system_prompt
    }
  }
  
  // Fallback para m√≥dulo padr√£o
  const defaultConfig = config.chat_modules?.default || config.chat_modules?.professor
  return defaultConfig?.system_prompt || 'Voc√™ √© um assistente educacional.'
}

/**
 * Obt√©m a configura√ß√£o completa de um m√≥dulo
 */
export function getModuleConfig(module: string): SystemMessageConfig | null {
  const config = loadSystemMessages()
  
  // Buscar em todas as categorias
  const allCategories = ['chat_modules', 'classification', 'api_routes', 'interactive_lessons', 'specialized_features']
  for (const category of allCategories) {
    const categoryConfig = config[category]?.[module]
    if (categoryConfig) {
      return categoryConfig
    }
  }
  
  return null
}

/**
 * Obt√©m todos os m√≥dulos dispon√≠veis
 */
export function getAvailableModules(): string[] {
  const config = loadSystemMessages()
  const modules: string[] = []
  
  // Coletar m√≥dulos de todas as categorias
  const allCategories = ['chat_modules', 'classification', 'api_routes', 'interactive_lessons', 'specialized_features']
  for (const category of allCategories) {
    if (config[category]) {
      modules.push(...Object.keys(config[category]))
    }
  }
  
  return [...new Set(modules)] // Remove duplicatas
}

/**
 * Obt√©m configura√ß√£o padr√£o em caso de erro
 */
function getDefaultSystemMessages(): SystemMessagesConfig {
  return {
    chat_modules: {
      professor: {
        name: 'Professor',
        description: 'Assistente educacional',
        system_prompt: 'Voc√™ √© um assistente educacional especializado em ajudar estudantes brasileiros.',
        temperature: 0.7,
        max_tokens: 1000,
        max_completion_tokens: 800,
        tone: 'motivacional',
        is_active: true
      },
      default: {
        name: 'Assistente Geral',
        description: 'Assistente educacional inteligente',
        system_prompt: 'Voc√™ √© um assistente educacional inteligente.',
        temperature: 0.7,
        max_tokens: 800,
        max_completion_tokens: 600,
        tone: 'educativo',
        is_active: true
      }
    }
  }
}

/**
 * For√ßa o reload do cache (√∫til para desenvolvimento)
 */
export function reloadSystemMessages(): void {
  systemMessagesCache = null
  lastModified = 0
  console.log('üîÑ System messages cache cleared')
}

/**
 * Valida se um m√≥dulo existe e est√° ativo
 */
export function isModuleActive(module: string): boolean {
  const config = loadSystemMessages()
  const moduleConfig = config[module]
  return moduleConfig ? moduleConfig.is_active : false
}

/**
 * Obt√©m configura√ß√µes de temperatura e tokens para um m√≥dulo
 */
export function getModuleSettings(module: string): {
  temperature: number
  max_tokens: number
  max_completion_tokens: number
} {
  const config = loadSystemMessages()
  const moduleConfig = config[module] || config.default || config.professor
  
  return {
    temperature: moduleConfig?.temperature || 0.7,
    max_tokens: moduleConfig?.max_tokens || 800,
    max_completion_tokens: moduleConfig?.max_completion_tokens || 600
  }
}
