# Sistema Universal de Fallback de IA

Este sistema implementa um fallback autom√°tico robusto entre diferentes provedores de IA usando o Vercel AI SDK. Quando um modelo falha (por quota, erro de API, timeout, etc.), o sistema automaticamente tenta outros provedores dispon√≠veis.

## üöÄ Caracter√≠sticas Principais

- **Fallback Autom√°tico**: Troca automaticamente entre provedores quando um falha
- **Detec√ß√£o Inteligente de Erros**: Identifica erros de quota, API key inv√°lida, timeout, etc.
- **Monitoramento de Sa√∫de**: Rastreia a sa√∫de de cada provedor e aplica backoff
- **Configura√ß√£o Flex√≠vel**: Suporta m√∫ltiplos provedores e modelos
- **Logs Detalhados**: Rastreamento completo de tentativas e fallbacks
- **Middleware Universal**: Pode ser usado em qualquer endpoint de IA

## üìã Provedores Suportados

| Provedor | Modelos | Prioridade | Status |
|----------|---------|------------|--------|
| OpenAI | GPT-4o Mini, GPT-4o, GPT-5 | 1 | ‚úÖ Ativo |
| Google Gemini | Gemini 1.5 Flash, Gemini 1.5 Pro | 2 | ‚úÖ Ativo |
| Perplexity AI | Sonar | 3 | ‚úÖ Ativo |
| Anthropic Claude | Claude 3 Haiku, Claude 3 Sonnet | 4 | üîß Opcional |

## üõ†Ô∏è Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# OpenAI (Prioridade 1)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Google Gemini (Prioridade 2)
GOOGLE_GENERATIVE_AI_API_KEY=your-gemini-api-key-here
# OU
GOOGLE_GEMINI_API_KEY=your-gemini-api-key-here
# OU
GOOGLE_API_KEY=your-gemini-api-key-here

# Perplexity AI (Prioridade 3)
PERPLEXITY_API_KEY=your-perplexity-api-key-here
PERPLEXITY_MODEL_SELECTION=sonar

# Anthropic Claude (Prioridade 4 - Opcional)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
```

### Instala√ß√£o

O sistema j√° est√° integrado ao projeto. N√£o s√£o necess√°rias depend√™ncias adicionais.

## üìñ Como Usar

### 1. Uso B√°sico com Middleware

```typescript
import { withAIFallback } from '@/lib/ai-middleware'

// Handler original
async function originalHandler(request: NextRequest, options: AIMiddlewareOptions) {
  // Sua l√≥gica espec√≠fica aqui
  // Se falhar, o middleware automaticamente tentar√° outros provedores
  throw new Error('Provider failed')
}

// Endpoint com fallback autom√°tico
export const POST = withAIFallback(originalHandler, {
  module: 'professor',
  complexity: 'simple',
  temperature: 0.7,
  maxTokens: 4000,
  timeout: 30000,
  maxRetries: 3
})
```

### 2. Uso Direto do Fallback Manager

```typescript
import { executeWithFallback } from '@/lib/ai-fallback-manager'

const result = await executeWithFallback({
  message: 'Sua pergunta aqui',
  module: 'professor',
  complexity: 'simple',
  systemPrompt: 'Prompt personalizado (opcional)',
  temperature: 0.7,
  maxTokens: 4000,
  timeout: 30000,
  maxRetries: 3,
  preferredProvider: 'openai', // For√ßar provedor espec√≠fico
  excludeProviders: ['google'] // Excluir provedores espec√≠ficos
})

if (result.success) {
  console.log('Resposta:', result.content)
  console.log('Provedor usado:', result.provider)
  console.log('Modelo:', result.model)
  console.log('Lat√™ncia:', result.latency)
  console.log('Tentativas:', result.attempts)
  console.log('Cadeia de fallback:', result.fallbackChain)
} else {
  console.error('Erro:', result.error)
}
```

### 3. Hooks Pr√©-configurados

```typescript
import { createChatEndpoint, createLessonEndpoint, createClassificationEndpoint } from '@/lib/ai-middleware'

// Para endpoints de chat
export const POST = createChatEndpoint({
  module: 'professor',
  complexity: 'simple'
})

// Para endpoints de gera√ß√£o de aulas
export const POST = createLessonEndpoint({
  complexity: 'complex',
  temperature: 0.8
})

// Para endpoints de classifica√ß√£o
export const POST = createClassificationEndpoint({
  complexity: 'fast'
})
```

## üîß Configura√ß√µes Avan√ßadas

### Op√ß√µes do Fallback Manager

```typescript
interface FallbackOptions {
  message: string                    // Mensagem para processar
  module?: string                   // M√≥dulo ('professor', 'enem', 'ti', etc.)
  complexity?: 'simple' | 'complex' | 'fast'  // N√≠vel de complexidade
  systemPrompt?: string             // Prompt do sistema personalizado
  temperature?: number              // Temperatura (0.0 - 1.0)
  maxTokens?: number                // M√°ximo de tokens
  timeout?: number                  // Timeout em ms
  maxRetries?: number               // M√°ximo de tentativas
  preferredProvider?: string        // Provedor preferido
  excludeProviders?: string[]      // Provedores a excluir
}
```

### Op√ß√µes do Middleware

```typescript
interface AIMiddlewareOptions {
  module?: string                   // M√≥dulo padr√£o
  complexity?: 'simple' | 'complex' | 'fast'  // Complexidade padr√£o
  systemPrompt?: string             // Prompt padr√£o
  temperature?: number              // Temperatura padr√£o
  maxTokens?: number                // Tokens padr√£o
  timeout?: number                  // Timeout padr√£o
  maxRetries?: number               // Tentativas padr√£o
  preferredProvider?: string        // Provedor preferido
  excludeProviders?: string[]       // Provedores exclu√≠dos
  enableCaching?: boolean           // Habilitar cache
  cacheKey?: string                 // Chave de cache personalizada
}
```

## üìä Monitoramento

### Endpoint de Status

```bash
GET /api/ai-fallback/status
```

Retorna:
- Status de todos os provedores
- Configura√ß√µes de ambiente
- Recomenda√ß√µes de melhoria
- Estat√≠sticas de sa√∫de

### Reset de Provedor

```bash
POST /api/ai-fallback/status
{
  "providerId": "openai",
  "action": "reset"
}
```

### Logs

O sistema gera logs detalhados com prefixos:
- `ü§ñ [AI-FALLBACK]`: Opera√ß√µes do sistema de fallback
- `üéØ [PROVIDER-SELECTION]`: Sele√ß√£o de provedores
- `üîÑ [FALLBACK]`: Tentativas de fallback
- `‚ùå [AI-ERROR]`: Erros de IA
- `‚úÖ [AI-SUCCESS]`: Sucessos

## üß™ Testes

### Script de Teste Autom√°tico

```bash
node test-ai-fallback-system.cjs
```

O script testa:
- Status dos provedores
- Requisi√ß√µes simples
- M√∫ltiplas requisi√ß√µes
- Fallback for√ßado
- Diferentes complexidades

### Teste Manual

```bash
# Testar endpoint de exemplo
curl -X POST http://localhost:3000/api/ai-fallback/example \
  -H "Content-Type: application/json" \
  -d '{"message": "Teste de fallback"}'

# Verificar status
curl http://localhost:3000/api/ai-fallback/status
```

## üîç Detec√ß√£o de Erros

O sistema detecta automaticamente:

### Erros de Quota
- `quota exceeded`
- `rate limit`
- `limit exceeded`
- `too many requests`
- C√≥digo HTTP 429

### Erros de API Key
- `api key`
- `authentication`
- `unauthorized`
- C√≥digo HTTP 401

### Erros de Timeout
- Timeout de conex√£o
- Timeout de resposta
- Timeout configurado

## üìà Estrat√©gias de Fallback

### 1. Fallback por Prioridade
1. OpenAI GPT-4o Mini (mais r√°pido e confi√°vel)
2. Google Gemini (boa qualidade, contexto extenso)
3. Perplexity AI (pesquisa e informa√ß√µes atualizadas)
4. Anthropic Claude (m√°xima qualidade, se configurado)

### 2. Fallback por Complexidade
- **Simples**: OpenAI GPT-4o Mini ou Google Gemini Flash
- **Complexa**: OpenAI GPT-4o ou Google Gemini Pro
- **R√°pida**: OpenAI GPT-4o Mini ou Google Gemini Flash

### 3. Fallback por M√≥dulo
- **Professor**: OpenAI preferido
- **ENEM**: OpenAI para quest√µes complexas
- **TI**: OpenAI para c√≥digo
- **Financeiro**: OpenAI para c√°lculos

## üö® Troubleshooting

### Problema: Nenhum provedor dispon√≠vel
**Solu√ß√£o**: Verifique se pelo menos uma API key est√° configurada

### Problema: Todos os provedores falhando
**Solu√ß√£o**: 
1. Verifique as API keys
2. Verifique os limites de quota
3. Verifique a conectividade de rede
4. Use o endpoint de status para diagn√≥stico

### Problema: Fallback muito lento
**Solu√ß√£o**:
1. Reduza o timeout
2. Reduza o n√∫mero de tentativas
3. Configure provedores preferidos
4. Use cache quando poss√≠vel

### Problema: Respostas inconsistentes
**Solu√ß√£o**:
1. Configure system prompts espec√≠ficos
2. Ajuste a temperatura
3. Use provedores preferidos para consist√™ncia

## üîÑ Migra√ß√£o de Endpoints Existentes

Para migrar um endpoint existente:

1. **Identifique o handler atual**:
```typescript
// Antes
export async function POST(request: NextRequest) {
  // L√≥gica existente
}
```

2. **Extraia a l√≥gica para um handler**:
```typescript
// Depois
async function originalHandler(request: NextRequest, options: AIMiddlewareOptions) {
  // L√≥gica existente movida para c√°
}

export const POST = withAIFallback(originalHandler, {
  // Configura√ß√µes espec√≠ficas
})
```

3. **Teste o fallback**:
```bash
node test-ai-fallback-system.cjs
```

## üìù Exemplos Completos

### Endpoint de Chat com Fallback

```typescript
import { withAIFallback } from '@/lib/ai-middleware'

async function chatHandler(request: NextRequest, options: AIMiddlewareOptions) {
  const body = await request.json()
  const { message, history = [] } = body
  
  // Valida√ß√µes espec√≠ficas
  if (!message?.trim()) {
    throw new Error('Message is required')
  }
  
  // Processamento espec√≠fico (cache, valida√ß√µes, etc.)
  // ...
  
  // Se chegou at√© aqui, o handler original funcionou
  return NextResponse.json({
    success: true,
    message: 'Chat processed successfully',
    timestamp: new Date().toISOString()
  })
}

export const POST = withAIFallback(chatHandler, {
  module: 'professor',
  complexity: 'simple',
  temperature: 0.7,
  maxTokens: 4000,
  timeout: 30000,
  maxRetries: 3,
  enableCaching: true
})
```

### Endpoint de Gera√ß√£o de Aulas com Fallback

```typescript
import { withAIFallback } from '@/lib/ai-middleware'

async function lessonHandler(request: NextRequest, options: AIMiddlewareOptions) {
  const body = await request.json()
  const { topic, level, subject } = body
  
  // Valida√ß√µes espec√≠ficas para aulas
  if (!topic?.trim()) {
    throw new Error('Topic is required')
  }
  
  // Processamento espec√≠fico para aulas
  // ...
  
  return NextResponse.json({
    success: true,
    lesson: 'Lesson generated successfully',
    timestamp: new Date().toISOString()
  })
}

export const POST = withAIFallback(lessonHandler, {
  module: 'aula_interativa',
  complexity: 'complex',
  temperature: 0.8,
  maxTokens: 6000,
  timeout: 45000,
  maxRetries: 2
})
```

## üéØ Benef√≠cios

1. **Alta Disponibilidade**: Sistema sempre funcionando mesmo com falhas de provedores
2. **Redund√¢ncia**: M√∫ltiplos provedores garantem continuidade
3. **Otimiza√ß√£o de Custos**: Usa provedores mais baratos quando poss√≠vel
4. **Qualidade Consistente**: Fallback inteligente mant√©m qualidade
5. **Monitoramento**: Visibilidade completa do sistema
6. **Facilidade de Uso**: Middleware simples para qualquer endpoint
7. **Flexibilidade**: Configura√ß√£o granular por endpoint

## üîÆ Pr√≥ximos Passos

- [ ] Suporte a mais provedores (Mistral, Groq, etc.)
- [ ] Fallback baseado em custo
- [ ] Fallback baseado em lat√™ncia
- [ ] Cache inteligente de respostas
- [ ] M√©tricas avan√ßadas de performance
- [ ] Dashboard de monitoramento
- [ ] Alertas autom√°ticos de falhas

---

**Desenvolvido com ‚ù§Ô∏è para garantir que sua aplica√ß√£o sempre tenha IA dispon√≠vel!**
